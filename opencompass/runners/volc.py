import os
import os.path as osp
import random
import subprocess
import time
from functools import partial
from typing import Any, Dict, List, Tuple
import re
import mmengine
from mmengine.config import ConfigDict
from mmengine.utils import track_parallel_progress

from opencompass.registry import RUNNERS, TASKS
from opencompass.utils import get_logger

from .base import BaseRunner


@RUNNERS.register_module()
class VOLCRunner(BaseRunner):
    """Distributed runner based on Volcano Cloud Cluster (VCC).
    It will launch multiple tasks in parallel with the 'vcc' command. Please
    install and configure VCC first before using this runner.

    Args:
        task (ConfigDict): Task type config.
        volcano_cfg (ConfigDict): Volcano Cloud config.
        max_num_workers (int): Max number of workers. Default: 32.
        retry (int): Number of retries when job failed. Default: 2.
        debug (bool): Whether to run in debug mode. Default: False.
        lark_bot_url (str): Lark bot url. Default: None.
    """

    def __init__(self,
                 task: ConfigDict,
                 volcano_cfg: ConfigDict,
                 max_num_workers: int = 32,
                 retry: int = 2,
                 debug: bool = False,
                 lark_bot_url: str = None):
        super().__init__(task=task, debug=debug, lark_bot_url=lark_bot_url)
        self.volcano_cfg = volcano_cfg
        self.max_num_workers = max_num_workers
        self.retry = retry

    def launch(self, tasks: List[Dict[str, Any]]) -> List[Tuple[str, int]]:
        """Launch multiple tasks.

        Args:
            tasks (list[dict]): A list of task configs, usually generated by
                Partitioner.

        Returns:
            list[tuple[str, int]]: A list of (task name, exit code).
        """

        if not self.debug:
            status = track_parallel_progress(self._launch,
                                             tasks,
                                             nproc=self.max_num_workers,
                                             keep_order=False)
        else:
            status = [self._launch(task, random_sleep=False) for task in tasks]
        return status

    def _launch(self, task_cfg: ConfigDict, random_sleep: bool = True):
        """Launch a single task.

        Args:
            task_cfg (ConfigDict): Task config.
            random_sleep (bool): Whether to sleep for a random time before
                running the command. This avoids cluster error when launching
                multiple tasks at the same time. Default: True.

        Returns:
            tuple[str, int]: Task name and exit code.
        """

        task_type = self.task_cfg.type
        if isinstance(self.task_cfg.type, str):
            task_type = TASKS.get(task_type)
        task = task_type(task_cfg)
        num_gpus = task.num_gpus
        task_name = task.name
        # Build up VCC command
        pwd = os.getcwd()

        # Dump task config to file
        mmengine.mkdir_or_exist('tmp/')
        param_file = f'{pwd}/tmp/{os.getpid()}_params.py'
        task_cfg.dump(param_file)

        shell_cmd = (f'source {self.volcano_cfg["bashrc_path"]}; '
                     f'source {self.volcano_cfg["conda_path"]}; '
                     f'conda activate {self.volcano_cfg["conda_env_name"]}; '
                     f'cd {pwd}; '
                     '{task_cmd}')

        task_name = task_name[:128].replace("[","-").replace("]","").replace("/","-").replace(",","--").replace(".",'_')
        tmpl = ('volc ml_task submit'
                f" --conf '{self.volcano_cfg.volcano_config_path}'"
                f" --entrypoint '{shell_cmd}'"
                f' --task_name {task_name}')
        get_cmd = partial(task.get_command, cfg_path=param_file, template=tmpl)
        cmd = get_cmd()

        logger = get_logger()
        logger.debug(f'Running command: {cmd}')

        # Run command with retry
        if self.debug:
            stdout = None
        else:
            out_path = task.get_log_path(file_extension='out')
            mmengine.mkdir_or_exist(osp.split(out_path)[0])
            stdout = open(out_path, 'w', encoding='utf-8')

        if random_sleep:
            time.sleep(random.randint(0, 10))
        result = subprocess.run(cmd,
                                shell=True,
                                text=True,
                                capture_output=True)
        pattern = r"(?<=task_id=).*(?=\n\n)"
        match = re.search(pattern, result.stdout)
        if match:
            task_id = match.group()
            ask_cmd = f"volc ml_task get --id {task_id} --output json --format Status"
            poll_interval = 20
            while True:
                task_status = os.popen(ask_cmd).read()
                pattern = r'(?<=\[{"Status":").*(?="}\])'
                match = re.search(pattern, task_status)
                if match:
                    task_status = match.group()
                else:
                    task_status = "Exception"
                if self.debug:
                    print(task_status)
                if task_status in ["Success", "Failed", "Cancelled", "Exception", "Killing"]:
                    break
                time.sleep(poll_interval)
        else:
            task_status = "Exception"
        retry = self.retry
        output_paths = task.get_output_paths()
        while self._job_failed(task_status, output_paths) and retry > 0:
            retry -= 1
            if random_sleep:
                time.sleep(random.randint(0, 10))
            # Re-generate command to refresh ports.
            cmd = get_cmd()
            result = subprocess.run(cmd,
                                    shell=True,
                                    text=True,
                                    capture_output=True)
            pattern = r"(?<=task_id=).*(?=\n\n)"
            match = re.search(pattern, result.stdout)
            if match:
                task_id = match.group()
                ask_cmd = f"volc ml_task get --id {task_id} --output json --format Status"
                poll_interval = 20
                while True:
                    task_status = os.popen(ask_cmd).read()
                    pattern = r'(?<=\[{"Status":").*(?="}\])'
                    match = re.search(pattern, task_status)
                    if match:
                        task_status = match.group()
                    else:
                        task_status = "Exception"
                    if self.debug:
                        print(task_status)
                    if task_status in ["Success", "Failed", "Cancelled", "Exception", "Killing"]:
                        break
                    time.sleep(poll_interval)
            else:
                task_status = "Exception"

        # Clean up
        os.remove(param_file)
        return task_name, result.returncode

    def _job_failed(self, task_status: str, output_paths: List[str]) -> bool:
        return task_status != "Success" or not all(
            osp.exists(output_path) for output_path in output_paths)
